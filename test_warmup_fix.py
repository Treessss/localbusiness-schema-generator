#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æµè§ˆå™¨é¢„çƒ­æœºåˆ¶ä¿®å¤æ•ˆæœ

è¿™ä¸ªè„šæœ¬ç”¨äºéªŒè¯æ·»åŠ é¢„çƒ­æœºåˆ¶åï¼Œæ˜¯å¦è§£å†³äº†éœ€è¦å…ˆè¿è¡Œtest_browser_basic.pyçš„é—®é¢˜ã€‚
ç›´æ¥æµ‹è¯•GoogleBusinessCrawlerçš„å¯åŠ¨å’Œé¡µé¢åˆ›å»ºåŠŸèƒ½ã€‚
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.crawler import GoogleBusinessCrawler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

async def test_direct_crawler_start():
    """ç›´æ¥æµ‹è¯•GoogleBusinessCrawlerå¯åŠ¨ï¼Œä¸ä¾èµ–test_browser_basic.py"""
    logger.info("=== æµ‹è¯•ç›´æ¥å¯åŠ¨GoogleBusinessCrawler ===")
    
    crawler = None
    
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        logger.info("åˆ›å»ºGoogleBusinessCrawlerå®ä¾‹...")
        crawler = GoogleBusinessCrawler()
        
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆåŒ…å«é¢„çƒ­æœºåˆ¶ï¼‰
        logger.info("å¯åŠ¨æµè§ˆå™¨ï¼ˆåŒ…å«é¢„çƒ­æœºåˆ¶ï¼‰...")
        await crawler.start()
        
        # æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
        if crawler.browser and crawler.browser.is_connected():
            logger.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸå¹¶å·²è¿æ¥")
        else:
            logger.error("âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥æˆ–æœªè¿æ¥")
            return False
        
        # æµ‹è¯•åˆ›å»ºé¡µé¢ï¼ˆè¿™æ˜¯ä¹‹å‰å¡ä½çš„åœ°æ–¹ï¼‰
        logger.info("æµ‹è¯•åˆ›å»ºæ–°é¡µé¢...")
        page = await crawler.browser.new_page()
        logger.info("âœ… é¡µé¢åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç®€å•å¯¼èˆª
        logger.info("æµ‹è¯•é¡µé¢å¯¼èˆª...")
        await page.goto('https://www.google.com', wait_until='domcontentloaded', timeout=15000)
        title = await page.title()
        logger.info(f"âœ… é¡µé¢å¯¼èˆªæˆåŠŸï¼Œæ ‡é¢˜: {title}")
        
        # å…³é—­æµ‹è¯•é¡µé¢
        await page.close()
        logger.info("æµ‹è¯•é¡µé¢å·²å…³é—­")
        
        logger.info("=== ç›´æ¥å¯åŠ¨æµ‹è¯•æˆåŠŸ ===")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç›´æ¥å¯åŠ¨æµ‹è¯•å¤±è´¥: {e}")
        return False
        
    finally:
        if crawler:
            try:
                await crawler.stop()
                logger.info("çˆ¬è™«å®ä¾‹å·²åœæ­¢")
            except Exception as e:
                logger.warning(f"åœæ­¢çˆ¬è™«æ—¶å‡ºé”™: {e}")

async def test_business_extraction():
    """æµ‹è¯•å•†å®¶ä¿¡æ¯æå–åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•å•†å®¶ä¿¡æ¯æå–åŠŸèƒ½ ===")
    
    crawler = None
    
    try:
        # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        async with GoogleBusinessCrawler() as crawler:
            logger.info("ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯åŠ¨çˆ¬è™«")
            
            # æµ‹è¯•URL
            test_url = "https://maps.app.goo.gl/XCLKuyn4vj9qrijE7"
            logger.info(f"æµ‹è¯•æå–å•†å®¶ä¿¡æ¯: {test_url}")
            
            # æå–å•†å®¶ä¿¡æ¯
            business_info = await crawler.extract_business_info(test_url)
            
            # æ£€æŸ¥ç»“æœ
            if business_info and business_info.get('name'):
                logger.info(f"âœ… å•†å®¶ä¿¡æ¯æå–æˆåŠŸ")
                logger.info(f"å•†å®¶åç§°: {business_info.get('name')}")
                logger.info(f"è¯„åˆ†: {business_info.get('rating')}")
                logger.info(f"åœ°å€: {business_info.get('address')}")
                return True
            else:
                logger.error("âŒ å•†å®¶ä¿¡æ¯æå–å¤±è´¥æˆ–ç»“æœä¸ºç©º")
                return False
                
    except Exception as e:
        logger.error(f"âŒ å•†å®¶ä¿¡æ¯æå–æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    logger.info(f"æ“ä½œç³»ç»Ÿ: {sys.platform}")
    logger.info("å¼€å§‹æµ‹è¯•æµè§ˆå™¨é¢„çƒ­æœºåˆ¶ä¿®å¤æ•ˆæœ...")
    
    # æµ‹è¯•1: ç›´æ¥å¯åŠ¨çˆ¬è™«
    test1_success = await test_direct_crawler_start()
    
    if test1_success:
        logger.info("åŸºç¡€å¯åŠ¨æµ‹è¯•é€šè¿‡ï¼Œç»§ç»­å•†å®¶ä¿¡æ¯æå–æµ‹è¯•")
        
        # æµ‹è¯•2: å•†å®¶ä¿¡æ¯æå–
        test2_success = await test_business_extraction()
        
        if test2_success:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¢„çƒ­æœºåˆ¶ä¿®å¤æˆåŠŸï¼")
            logger.info("ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨GoogleBusinessCrawlerï¼Œæ— éœ€å…ˆè¿è¡Œtest_browser_basic.py")
        else:
            logger.error("å•†å®¶ä¿¡æ¯æå–æµ‹è¯•å¤±è´¥")
    else:
        logger.error("åŸºç¡€å¯åŠ¨æµ‹è¯•å¤±è´¥ï¼Œé¢„çƒ­æœºåˆ¶å¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")

if __name__ == "__main__":
    asyncio.run(main())